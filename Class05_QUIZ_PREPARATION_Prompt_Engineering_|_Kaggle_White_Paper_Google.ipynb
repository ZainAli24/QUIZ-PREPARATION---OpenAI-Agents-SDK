{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyxKSwWWZorFsiMmro7KYO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZainAli24/QUIZ-PREPARATION---OpenAI-Agents-SDK/blob/main/Class05_QUIZ_PREPARATION_Prompt_Engineering_%7C_Kaggle_White_Paper_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Engineering ke Topics ki Samajh (PDF se)\n",
        "\n",
        "PDF \"Prompt Engineering_v7\" ek comprehensive guide hai jo Large Language Models (LLMs) ke liye prompts banane ke techniques, configurations, aur best practices ko cover karti hai. Ye graduate-level ke students ke liye deep understanding provide karti hai. Niche PDF mein mention key topics aur unki samajh di gayi hai:\n",
        "\n",
        "1. **LLM Output Configuration**:\n",
        "   - **Output Length**: Ye control karta hai ki model kitne tokens generate karega. Zyada tokens se computation, cost, aur time badhta hai.\n",
        "   - **Sampling Controls**: Ye output ki randomness aur quality ko adjust karte hain:\n",
        "\n",
        "    ### 1. **Temperature**\n",
        "    - **Kya hai yeh?**: Temperature control karta hai ke model kitna random ya predictable response deta hai.\n",
        "      - **Low temperature (e.g., 0.1)**: Jab temperature kam hota hai, toh model woh tokens (words) choose karta hai jo uske hisaab se sabse zyada probable hote hain. Yani, woh \"safe\" option leta hai, jisse response focused aur point-to-point hota hai.\n",
        "      - **High temperature (e.g., 1.0 ya usse zyada)**: Jab temperature zyada hota hai, toh model kam probable tokens bhi select kar sakta hai. Isse response zyada creative, unexpected, ya kabhi-kabhi thoda sa off-topic bhi ho sakta hai.\n",
        "\n",
        "    - **Simple language mein**:\n",
        "      - Low temperature = seedha aur predictable jawab.\n",
        "      - High temperature = random aur creative jawab.\n",
        "\n",
        "    - **Aapki samajh**: Aapne bilkul sahi kaha! Low temperature mein model high-probability tokens pe focus karta hai, aur high temperature mein randomness badh jata hai.\n",
        "\n",
        "    ### 2. **Top-k Sampling**\n",
        "    - **Kya hai yeh?**: Top-k ka matlab hai ke model apne input ke base pe top k most probable tokens mein se hi choose karta hai.\n",
        "      - **Low top-k (e.g., 5)**: Agar aap top-k ko 5 rakhte hain, toh model sirf top 5 probable tokens hi dekhta hai. Isse response focused ho sakta hai, lekin agar yeh 5 options perfect na hon, toh model galat jawab bhi de sakta hai.\n",
        "      - **High top-k (e.g., 50)**: Agar top-k zyada hai, toh model zyada tokens consider karta hai, jisse variety toh aati hai, lekin response kabhi-kabhi kam relevant ho sakta hai.\n",
        "\n",
        "    - **Aapka image example**:\n",
        "      - Maan lo aapne 5 images di hain: Image-1 (80% probability), Image-2 (20%), Image-3 (12%), Image-4 (5%), Image-5 (3%).\n",
        "      - Agar top-k = 3 rakha, toh model sirf Image-1, Image-2, aur Image-3 ko dekhega. Ab yeh teeno mein se koi bhi choose kar sakta hai, chahe Image-1 sabse zy 80% match ho. Problem yeh hai ke Image-1 sabse zyada probable hai, lekin model phir bhi Image-2 ya Image-3 le sakta hai, jisse result galat ho sakta hai.\n",
        "      - Agar top-k high hota hai (jaise 4 ya 5), toh model aur options dekhta hai, lekin phir bhi randomly choose karta hai.\n",
        "\n",
        "    - **Key point**: Top-k fixed number of options pe kaam karta hai, chahe unki probability kitni bhi ho.\n",
        "\n",
        "    ### 3. **Top-p Sampling (Nucleus Sampling)**\n",
        "    - **Kya hai yeh?**: Top-p mein model tokens ko unki cumulative probability ke base pe select karta hai jab tak ek threshold (p) tak na pahunch jaye, jaise 0.9 (90%).\n",
        "      - Yani, model sabse probable tokens se shuru karta hai aur tab tak add karta hai jab tak total probability p tak na pahunch jaye.\n",
        "      - Isse model flexibly kaam karta hai—na zyada narrow, na zyada broad.\n",
        "\n",
        "    - **Aapka image example**:\n",
        "      - Agar aap p = 0.8 (80%) rakhte hain, toh model woh images choose karega jinka total probability 80% tak jata hai.\n",
        "      - Example: Agar Image-1 80% pe hai, toh model sirf usko lega, kyunki threshold poora ho gaya. Agar Image-1 50% pe hai, toh woh Image-2 (30%) ko bhi add karega taaki 80% tak pahunch jaye.\n",
        "      - Isse faida yeh hai ke model sabse relevant option pe focus karta hai.\n",
        "\n",
        "    - **Key point**: Top-p dynamic hota hai aur probability ke hisaab se adjust hota hai, fixed number pe nahi rukta jaise top-k.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **In Teeno Mein Fark**\n",
        "    - **Temperature**: Randomness control karta hai. Low = predictable, high = creative.\n",
        "    - **Top-k**: Top fixed number of probable options mein se chunta hai. Low k = focused, high k = zyada variety.\n",
        "    - **Top-p**: Probability ke base pe threshold tak options leta hai. Yeh relevant options pe focus karta hai.\n",
        "\n",
        "    ### **Aapke Image Example Ki Wajah Se Confusion**\n",
        "    - Temperature, top-k, aur top-p zyadatar text generation mein use hote hain, lekin inka concept image matching jaise tasks pe bhi apply ho sakta hai.\n",
        "    - Text mein yeh parameters decide karte hain ke kaunse words choose karne hain unki probability ke base pe.\n",
        "    - Same tarah, image matching mein har image ke liye probability hoti hai (jaise 80%, 20%), aur in sampling methods se decide ho sakta hai ke kaunsi images consider karni hain.\n",
        "\n",
        "---\n",
        "\n",
        "2. **Prompting Techniques**:\n",
        "  Aapko zero-shot aur one-shot prompting samajh nahi aaya, koi baat nahi! Main ise aapko bilkul simple language mein, examples ke saath samjhaungi taaki aapka confusion door ho jaye. Chaliye step-by-step dekhte hain.\n",
        "\n",
        "    ### **1. Zero-Shot Prompting Kya Hai?**\n",
        "    - **Matlab**: Zero-shot prompting mein aap model ko sirf task batate hain, lekin koi example nahi dete. Model apne pehle se seekhe hue knowledge ke base par jawab deta hai.\n",
        "    - **Example Diya Jata Hai Ya Nahi?**: **Nahi**, koi bhi example nahi diya jata.\n",
        "    - **Kaise Kaam Karta Hai?**: Aap bas bolte hain \"yeh karo,\" aur model khud samajh jata hai (agar usne pehle se seekha hai toh).\n",
        "\n",
        "    **Example**:\n",
        "    - **Prompt**: \"Is sentence ko French mein translate karo: 'Hello, how are you?'\"\n",
        "    - **Jawab**: Model bolega \"Bonjour, comment vas-tu?\"\n",
        "    - **Kyun?**: Yahaan aapne koi example nahi diya ke translation kaise hota hai. Model ne apne training se khud decide kiya.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **2. One-Shot Prompting Kya Hai?**\n",
        "    - **Matlab**: One-shot prompting mein aap model ko task batate hain aur **ek example** dete hain taaki model samajh jaye ke aap kya chahte hain.\n",
        "    - **Example Diya Jata Hai Ya Nahi?**: **Haan**, ek example diya jata hai.\n",
        "    - **Kaise Kaam Karta Hai?**: Aap pehle ek chhota sa hint dete hain (example ke through), phir model us hint ko follow karke jawab deta hai.\n",
        "\n",
        "    **Example**:\n",
        "    - **Prompt**: \"Translate 'Good morning' to French: 'Bonjour'. Ab is sentence ko French mein translate karo: 'Hello, how are you?'\"\n",
        "    - **Jawab**: Model bolega \"Bonjour, comment vas-tu?\"\n",
        "    - **Kyun?**: Yahaan aapne pehle ek example diya (\"Good morning\" = \"Bonjour\"), toh model samajh gaya ke translation ka pattern kya hai, aur usne doosre sentence ko bhi translate kar diya.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **Aapke Confusion Ka Jawab**\n",
        "    - **\"Example kaise di jati hai aur kaise nahi di jati?\"**  \n",
        "      - Zero-shot mein **koi example nahi dete**, sirf sawal poochte hain. Jaise \"Yeh karo\" aur bas.\n",
        "      - One-shot mein **ek example dete hain**, taaki model ko idea ho ke aap kya expect kar rahe hain.\n",
        "    - **Agar samajh nahi aaya toh**: Zero-shot mein model ko kuch extra help nahi milti, jabki one-shot mein ek chhota sa hint milta hai.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **Chhota Sa Summary**\n",
        "    - **Zero-Shot**: \"Bina hint ke kaam karo.\"\n",
        "    - **One-Shot**: \"Ek hint ke saath kaam karo.\"\n",
        "-------\n",
        "\n",
        "   - **System, Contextual, aur Role Prompting**:\n",
        "\n",
        "    ### **1. System Prompting**\n",
        "    - **Kya Hai**: System prompting mein hum LLM ko ek **khas task** dete hain ya ye batate hain ke us ne **kis tarah ka output dena hai**. Yani hum model ko saaf saaf hukum dete hain ke \"ye kaam karo\" ya \"is format mein jawab do.\"\n",
        "    - **Maksad**: Is ka maqsad ye hai ke LLM ko pata ho ke us ne kya karna hai aur us ka jawab humari zarurat ke mutabiq ho.\n",
        "    - **Misaal**:\n",
        "      - Agar hum kehte hain: \"Is film review ko positive ya negative classify karo,\" to ye ek task hai jo system prompting ke zariye diya gaya.\n",
        "      - Ya phir: \"Jawab JSON format mein do jismein 'sentiment' aur 'confidence' keys hon,\" to ye output format batane wali misaal hai.\n",
        "    - **Faida**: Ye technique model ko direction deti hai ke kaam kis tarah karna hai.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **2. Context Prompting**\n",
        "    - **Kya Hai**: Context prompting mein hum apne **task se mutalliq details** ya **background information** dete hain. Yani hum model ko batate hain ke hamara topic kya hai aur us ke bare mein zaroori maloomat dete hain.\n",
        "    - **Maksad**: Is se model ko samajh aata hai ke hum kis cheez ke bare mein baat kar rahe hain, aur wo ziyada behtar aur munasib jawab de sakta hai.\n",
        "    - **Misaal**:\n",
        "      - Agar hum kehte hain: \"Main Amsterdam mein hoon aur sirf museums dekhna chahta hoon. Teen jagah suggest karo,\" to ye context hai ke main kahan hoon aur mujhe kya chahiye.\n",
        "      - Ya phir: \"Yeh blog 80’s ke arcade video games ke bare mein hai. Teen topics suggest karo,\" to ye context blog ke theme ko wazeh karta hai.\n",
        "    - **Faida**: Context dene se jawab ziyada relevant aur kaam ka hota hai.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **3. Role Prompting**\n",
        "    - **Kya Hai**: Role prompting mein hum LLM ko ek **khas role** dete hain, jaise \"tum ek teacher ho\" ya \"tum ek travel guide ho.\" Is ke baad LLM us role ke mutabiq jawab deta hai.\n",
        "    - **Maksad**: Ye style aur tone ko control karta hai, taki jawab us role ke shayan ho aur ziyada dilchasp ya munasib lage.\n",
        "    - **Misaal**:\n",
        "      - Agar hum kehte hain: \"Ek travel guide ki tarah Amsterdam ki teen jagah suggest karo,\" to model ek guide ki tarah jawab dega, shayad ziyada jazbati ya maloomati andaaz mein.\n",
        "      - Ya phir: \"Ek history teacher ban kar French Revolution ki ahmiyat samjhao,\" to model taleemi andaaz mein samjhayega.\n",
        "    - **Faida**: Role dene se jawab ka perspective aur andaaz badal jata hai jo humari zarurat ke mutabiq hota hai.\n",
        "\n",
        "    ### **Teeno Ko Sath Istemal Karna**\n",
        "    Aap in teeno ko milakar bhi istemal kar sakte hain. Maslan:\n",
        "    - **Prompt**: \"Tum ek travel guide ho (role). Amsterdam ke teen museums suggest karo (context). Jawab list format mein do (system).\"\n",
        "    - **Samajh**: Is mein role, context, aur output format sab shamil hain, jo ek munasib aur terteeb daar jawab dete hain.\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### **Kyun Zaroori Hain**\n",
        "    - **System Prompting** se model ko saaf direction milti hai.\n",
        "    - **Context Prompting** se jawab ziyada durust aur munasib hota hai.\n",
        "    - **Role Prompting** se jawab mein personality ya expertise aati hai.\n",
        "--------\n",
        "\n",
        "  ## **1. Step-Back Prompting**\n",
        "  ### **Kya Hai?**\n",
        "  Yeh ek tarika hai jisme pehle ek bada, general sawal poocha jata hai taaki model ko task ke baare mein background knowledge ya context mil jaye. Phir us context ke base par specific task solve kiya jata hai. Iska matlab hai ke pehle \"zoom out\" karke badi picture dekhi jati hai, phir \"zoom in\" karke chhoti problem solve ki jati hai.\n",
        "\n",
        "  ### **Kaise Kaam Karta Hai?**\n",
        "  Model ko pehle general knowledge ya related information yaad dilayi jati hai, jisse uska reasoning behtar hota hai aur woh specific sawal ka jawab zyada accurately de sakta hai.\n",
        "\n",
        "  ### **Example**\n",
        "  - **Task**: \"France ka capital kya hai?\"\n",
        "  - **Step-Back Prompt**: Pehle poocho, \"France ke baare mein kuch basic information kya hai? Ya France ke major cities kaunse hain?\"\n",
        "  - **Jawab**: Model sochta hai, \"France ek country hai Europe mein, aur iske bade shehar jaise Paris, Lyon, Marseille hain. Capital to Paris hi hoga.\"  \n",
        "  - Yani, pehle general soch kar model specific jawab \"Paris\" tak pahunchta hai.\n",
        "\n",
        "  ### **Daily Life Analogy**\n",
        "  Jab aapko kisi dost ka phone number yaad nahi hota, to pehle aap sochte hain, \"Woh kaunse college mein tha? Ya uska birthday kab hai?\" Yeh general cheezein yaad karke aapko number yaad aa jata hai. Step-Back Prompting bhi aise hi kaam karta hai.\n",
        "\n",
        "  ### **Faida**\n",
        "  - Model ko task ke liye zyada tayyar karta hai.\n",
        "  - Galtiyan kam hoti hain kyunki pehle context clear hota hai.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **2. Chain of Thought (CoT)**\n",
        "  ### **Kya Hai?**\n",
        "  Chain of Thought mein model ko kaha jata hai ke woh task ko step-by-step soch kar solve kare. Yeh khas kar complex tasks, jaise math ya logic problems, ke liye useful hai.\n",
        "\n",
        "  ### **Kaise Kaam Karta Hai?**\n",
        "  Model ko har step explain karne ke liye bola jata hai, jisse woh problem ko chhote chhote hisson mein todta hai aur ek ek karke solve karta hai.\n",
        "\n",
        "  ### **Example**\n",
        "  - **Task**: \"Agar ek train 60 km/h ki speed se chal rahi hai aur 120 km door hai, to kitna time lagega?\"\n",
        "  - **CoT Prompt**:\n",
        "    1. \"Pehle distance aur speed note karo: 120 km aur 60 km/h.\"\n",
        "    2. \"Time nikalne ka formula yaad karo: Time = Distance / Speed.\"\n",
        "    3. \"Ab values daalo: 120 / 60 = 2.\"\n",
        "    4. \"To jawab hai 2 hours.\"\n",
        "  - Model step-by-step sochta hai aur sahi jawab deta hai.\n",
        "\n",
        "  ### **Daily Life Analogy**\n",
        "  Jab aapko recipe banani ho aur aap har step follow karte hain—pehle ingredients collect karo, phir mix karo, phir bake karo—tab aapka khana perfect banta hai. CoT bhi model ko aise hi guide karta hai.\n",
        "\n",
        "  ### **Faida**\n",
        "  - Complex problems ko simple banata hai.\n",
        "  - Har step clear hone se galtiyan kam hoti hain.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **3. Self-Consistency**\n",
        "  ### **Kya Hai?**\n",
        "  Self-Consistency mein model ek hi sawal ke liye alag alag tareeqon se sochta hai (multiple reasoning paths), aur phir jo answer sabse zyada baar aata hai ya consistent hota hai, usko final answer maana jata hai.\n",
        "\n",
        "  ### **Kaise Kaam Karta Hai?**\n",
        "  Yeh technique jawab ko verify karti hai taaki galti na ho. Alag alag approaches se same answer aane par bharosa badhta hai.\n",
        "\n",
        "  ### **Example**\n",
        "  - **Task**: \"2 + 2 kitna hota hai?\"\n",
        "  - **Multiple Paths**:\n",
        "    1. \"2 apples + 2 apples = 4 apples.\"\n",
        "    2. \"2 fingers + 2 fingers = 4 fingers.\"\n",
        "    3. \"Mathematically, 2 + 2 = 4.\"\n",
        "  - **Result**: Har tareeke se jawab \"4\" aaya, to final answer \"4\" hai.\n",
        "\n",
        "  ### **Daily Life Analogy**\n",
        "  Jab aapko doubt ho ke aapne darwaza lock kiya ya nahi, to aap dobara check karte hain—ek baar memory se, ek baar jaakar dekh kar. Agar dono se confirm ho, to aap sure ho jate hain. Self-Consistency bhi aisa hi hai.\n",
        "\n",
        "  ### **Faida**\n",
        "  - Jawab ki accuracy badhti hai.\n",
        "  - Errors ko pakadna asan hota hai.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **4. Tree of Thoughts (ToT)**\n",
        "  ### **Kya Hai?**\n",
        "  Tree of Thoughts mein model ek problem ke liye ek saath kai reasoning paths explore karta hai, jaise ek tree ki branches. Yeh complex problems ke liye best hai jahan multiple solutions ho sakte hain.\n",
        "\n",
        "  ### **Kaise Kaam Karta Hai?**\n",
        "  Model alag alag tareeqon se sochta hai aur har path ko check karta hai, phir best solution chunta hai.\n",
        "\n",
        "  ### **Example**\n",
        "  - **Task**: \"Traffic kam kaise kiya ja sake?\"\n",
        "  - **Branches**:\n",
        "    1. \"Public transport ko behtar karo.\"\n",
        "    2. \"Work from home ko promote karo.\"\n",
        "    3. \"Naye roads banayein.\"\n",
        "  - **Result**: Model sochta hai aur decide karta hai ke kaunsa solution practical hai.\n",
        "\n",
        "  ### **Daily Life Analogy**\n",
        "  Jab aap picnic plan karte hain aur sochte hain—park jayein, beach jayein, ya ghar pe hi rahein—aur phir weather, budget dekhte hain to best option chunte hain. ToT bhi aise hi options explore karta hai.\n",
        "\n",
        "  ### **Faida**\n",
        "  - Multiple possibilities check karne ka mauka milta hai.\n",
        "  - Best solution tak pahunchne mein madad milti hai.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **5. ReAct (Reason & Act)**\n",
        "  ### **Kya Hai?**\n",
        "  ReAct mein model reasoning (sochne) aur action (kuch karne) ko ek loop mein milata hai. Yani, pehle sochta hai, phir kuch karta hai (jaise information dhundta hai), aur phir uske base par jawab deta hai.\n",
        "\n",
        "  ### **Kaise Kaam Karta Hai?**\n",
        "  Yeh tasks ke liye useful hai jahan sirf sochne se kaam nahi chalta, balki kuch actions (jaise search) bhi karne padte hain.\n",
        "\n",
        "  ### **Example**\n",
        "  - **Task**: \"Metallica band members ke kitne kids hain?\"\n",
        "  - **ReAct Process**:\n",
        "    1. **Reason**: \"Mujhe Metallica ke members ke naam pata hone chahiye.\"\n",
        "    2. **Act**: \"Search karo: Metallica band members—James Hetfield, Lars Ulrich, etc.\"\n",
        "    3. **Reason**: \"Ab har member ke kids count karo.\"\n",
        "    4. **Act**: \"Search karo: James Hetfield ke 3 kids hain, Lars Ulrich ke 2 hain.\"\n",
        "    5. **Final**: \"Total kids = 3 + 2 + ... = X.\"\n",
        "\n",
        "  ### **Daily Life Analogy**\n",
        "  Jab aapko kisi ka address chahiye, to pehle sochte hain \"Woh kaunse area mein rehta hai?\" phir phone karke poochte hain, aur phir confirm karte hain. ReAct bhi aise hi loop mein kaam karta hai.\n",
        "\n",
        "  ### **Faida**\n",
        "  - Real-world tasks ke liye perfect hai.\n",
        "  - Soch aur action mil kar behtar result dete hain.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **6. Automatic Prompt Engineering**\n",
        "  ### **Kya Hai?**\n",
        "  Isme model khud apne prompts banata hai aur unko refine karta hai taaki tasks zyada ache se solve ho sakein. Yeh ek advanced technique hai jahan model apne aap seekhta hai.\n",
        "\n",
        "  ### **Kaise Kaam Karta Hai?**\n",
        "  Model trial and error karta hai—pehle ek prompt try karta hai, dekhta hai ke kaam karta hai ya nahi, aur phir usko behtar banata hai.\n",
        "\n",
        "  ### **Example**\n",
        "  - **Task**: \"Customer ke orders ko JSON mein parse karo.\"\n",
        "  - **Process**:\n",
        "    1. Pehla Prompt: \"Order ko JSON mein convert karo.\"\n",
        "    2. Result acha nahi aaya, to refine karta hai.\n",
        "    3. Naya Prompt: \"Order se size aur price nikalo, phir JSON banayein.\"\n",
        "    4. Yeh behtar kaam karta hai, to model isko yaad rakhta hai.\n",
        "\n",
        "  ### **Daily Life Analogy**\n",
        "  Jab aap cooking seekhte hain—pehle salt zyada daal dete hain, phir next time kam karte hain, aur dheere dheere perfect recipe banate hain. Model bhi aise hi prompts ko perfect karta hai.\n",
        "\n",
        "  ### **Faida**\n",
        "  - Human effort kam lagta hai.\n",
        "  - Model khud efficient banta hai.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **Quick Summary**\n",
        "  - **Step-Back Prompting**: Pehle bada sawal, phir chhota jawab.\n",
        "  - **Chain of Thought**: Step-by-step soch kar solve karo.\n",
        "  - **Self-Consistency**: Alag tareeqon se check karke confirm karo.\n",
        "  - **Tree of Thoughts**: Kai options ek saath explore karo.\n",
        "  - **ReAct**: Socho, kaam karo, phir refine karo.\n",
        "  - **Automatic Prompt Engineering**: Model khud prompts banaye aur sudhare.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## **Kab Kaunsa Use Karna?**\n",
        "  - **Step-Back**: Jab context ya background chahiye.\n",
        "  - **CoT**: Jab complex problem ko todna ho.\n",
        "  - **Self-Consistency**: Jab accuracy zaroori ho.\n",
        "  - **ToT**: Jab multiple solutions explore karne hon.\n",
        "  - **ReAct**: Jab info gather aur soch dono zaroori hon.\n",
        "  - **Automatic Prompt**: Jab model ko independent banan ho.\n",
        "\n",
        "  ---\n",
        "\n",
        "  Umeed hai ab yeh concepts aapko clear ho gaye honge! Agar koi confusion baki hai ya kisi ek point ko aur samajhna hai, to mujhe zaroor bataiye—main aur detail mein explain kar dunga.\n",
        "\n",
        "\n",
        "\n",
        "  # Concepts Ki Detailed Samajh\n",
        "\n",
        "  ## 1. Step-Back Prompting\n",
        "  - **Kya Hai**: Pehle general sawal pooch kar background knowledge activate karna, phir specific task solve karna.\n",
        "  - **Example**: \"France ka capital?\" → Pehle \"France ke cities kaunse hain?\" → \"Paris.\"\n",
        "  - **Faida**: Reasoning behtar hota hai, galtiyan kam hoti hain.\n",
        "\n",
        "  ## 2. Chain of Thought (CoT)\n",
        "  - **Kya Hai**: Step-by-step soch kar complex tasks solve karna.\n",
        "  - **Example**: \"120 km 60 km/h se kitna time?\" → Step 1: Formula (Time = Distance / Speed) → Step 2: 120 / 60 = 2 hours.\n",
        "  - **Faida**: Complex problems asan ho jate hain.\n",
        "\n",
        "  ## 3. Self-Consistency\n",
        "  - **Kya Hai**: Multiple tareeqon se soch kar consistent answer chunna.\n",
        "  - **Example**: \"2 + 2?\" → Apples se 4, fingers se 4, math se 4 → Final: 4.\n",
        "  - **Faida**: Jawab reliable hota hai.\n",
        "\n",
        "  ## 4. Tree of Thoughts (ToT)\n",
        "  - **Kya Hai**: Ek saath kai reasoning paths explore karna.\n",
        "  - **Example**: \"Traffic kam kaise karo?\" → Public transport, WFH, new roads → Best solution chuno.\n",
        "  - **Faida**: Multiple options milte hain.\n",
        "\n",
        "  ## 5. ReAct (Reason & Act)\n",
        "  - **Kya Hai**: Reasoning aur action ko loop mein milana.\n",
        "  - **Example**: \"Metallica ke kids?\" → Socho → Search karo → Count karo.\n",
        "  - **Faida**: Real-world tasks ke liye perfect.\n",
        "\n",
        "  ## 6. Automatic Prompt Engineering\n",
        "  - **Kya Hai**: Model khud prompts banata aur refine karta hai.\n",
        "  - **Example**: \"Order ko JSON mein?\" → Pehla prompt fail → Refine karke better prompt.\n",
        "  - **Faida**: Human effort kam, efficiency zyada.\n",
        "\n",
        "  -----------\n",
        "\n",
        "3. **Code Prompting**:\n",
        "   - LLMs se code likhwana (e.g., Bash script), explain karwana, translate karna (e.g., Bash se Python), aur debug karna sikha jata hai.\n",
        "\n",
        "4. **Best Practices**:\n",
        "   - Examples dena, simple aur specific prompts likhna, instructions over constraints use karna, token length control karna, variables use karna, input/output formats experiment karna, aur prompt attempts document karna.\n",
        "\n",
        "Ye topics messages mein bhi reflect hote hain, jahan prompt engineering ke techniques (e.g., Chain of Thought, Tree of Thoughts) aur configurations (e.g., temperature, top-k) ka zikr hai, jo Agentic AI quizzes ke liye relevant hain.\n",
        "\n",
        "---\n",
        "\n",
        "### 20 Graduate-Level Quiz Questions\n",
        "\n",
        "Ab main 20 multiple-choice quiz questions banata hoon jo graduate-level ke liye challenging hon aur PDF ke topics ko cover karen. Har question ke 4 options honge, aur correct answer bold mein highlight hoga.\n",
        "\n",
        "#### Question 1\n",
        "Temperature ki value badhane se model ka output kaisa hoga?  \n",
        "a) Zyada deterministic banega  \n",
        "b) **Zyada random banega**  \n",
        "c) Koi asar nahi hoga  \n",
        "d) Output ki length kam ho jayegi  \n",
        "**Explanation**: High temperature randomness badhata hai, jaisa ki PDF ke \"Temperature\" section mein samjhaya gaya.\n",
        "\n",
        "#### Question 2\n",
        "Agar top-k ki value 1 set ki jaye, to model ka behavior kya hoga?  \n",
        "a) Random sampling  \n",
        "b) **Greedy decoding**  \n",
        "c) Beam search  \n",
        "d) Top-p sampling  \n",
        "**Explanation**: Top-k = 1 matlab sirf sabse probable token chuna jata hai, jo greedy decoding ke barabar hai.\n",
        "\n",
        "#### Question 3\n",
        "Kaunsi prompting technique mein examples nahi diye jate?  \n",
        "a) Few-shot  \n",
        "b) One-shot  \n",
        "c) **Zero-shot**  \n",
        "d) Contextual  \n",
        "**Explanation**: Zero-shot mein sirf task description hoti hai, examples nahi.\n",
        "\n",
        "#### Question 4\n",
        "Few-shot prompting mein multiple examples dene ka maksad kya hai?  \n",
        "a) Model ki creativity badhana  \n",
        "b) **Model ko desired pattern samjhana**  \n",
        "c) Token usage kam karna  \n",
        "d) Prompt ko lamba karna  \n",
        "**Explanation**: Examples pattern ko clear karte hain, jaisa ki PDF mein diya gaya.\n",
        "\n",
        "#### Question 5\n",
        "Step-back prompting ka main idea kya hai?  \n",
        "a) Model ko step-by-step sochne ke liye kaha jata hai  \n",
        "b) **Specific task se pehle general question puchha jata hai**  \n",
        "c) Tree structure use kiya jata hai  \n",
        "d) Reasoning aur acting combine kiya jata hai  \n",
        "**Explanation**: Step-back broader context activate karta hai.\n",
        "\n",
        "#### Question 6\n",
        "Chain of Thought (CoT) prompting kis ke liye sabse useful hai?  \n",
        "a) Creative writing  \n",
        "b) **Reasoning tasks**  \n",
        "c) Simple classification  \n",
        "d) Code generation  \n",
        "**Explanation**: CoT reasoning steps ke liye best hai, jaise math problems.\n",
        "\n",
        "#### Question 7\n",
        "Self-consistency prompting mein kya hota hai?  \n",
        "a) **Multiple reasoning paths generate karke consistent answer chuna jata hai**  \n",
        "b) Model hamesha same answer deta hai  \n",
        "c) Single chain of thought use hoti hai  \n",
        "d) Model khud apna kaam check karta hai  \n",
        "**Explanation**: Self-consistency diversity aur consistency balance karti hai.\n",
        "\n",
        "#### Question 8\n",
        "Code generation ke liye LLMs use karte waqt generated code review karna kyun zaroori hai?  \n",
        "a) LLMs hamesha correct code dete hain  \n",
        "b) **LLMs reasoning nahi kar sakte aur errors ho sakte hain**  \n",
        "c) Time bachane ke liye  \n",
        "d) Naye programming languages seekhne ke liye  \n",
        "**Explanation**: LLMs errors produce kar sakte hain, isliye review zaroori hai.\n",
        "\n",
        "#### Question 9\n",
        "Prompt engineering ka kaunsa best practice hai?  \n",
        "a) Complex language use karna  \n",
        "b) **Prompt mein examples dena**  \n",
        "c) Temperature hamesha 1 set karna  \n",
        "d) Structured output avoid karna  \n",
        "**Explanation**: Examples accuracy improve karte hain.\n",
        "\n",
        "#### Question 10\n",
        "Instructions constraints ke muqable kyun behtar hain?  \n",
        "a) Constraints implement karna mushkil hai  \n",
        "b) **Instructions clearer guidance dete hain**  \n",
        "c) Constraints creativity limit karte hain  \n",
        "d) Instructions chhote hote hain  \n",
        "**Explanation**: Instructions model ko directly guide karte hain.\n",
        "\n",
        "#### Question 11\n",
        "Temperature 0 set karne se kya hota hai?  \n",
        "a) Model zyada creative banega  \n",
        "b) **Model hamesha sabse probable token chunta hai**  \n",
        "c) Model random tokens deta hai  \n",
        "d) Model text generate nahi karta  \n",
        "**Explanation**: Temperature 0 greedy decoding ke barabar hai.\n",
        "\n",
        "#### Question 12\n",
        "Top-p sampling kya control karta hai?  \n",
        "a) Maximum tokens ki sankhya  \n",
        "b) **Cumulative probability threshold token selection ke liye**  \n",
        "c) Model ka temperature  \n",
        "d) Context window size  \n",
        "**Explanation**: Top-p nucleus sampling ke liye probability threshold set karta hai.\n",
        "\n",
        "#### Question 13\n",
        "Agar aapko JSON format mein response chahiye, to kaunsi technique best hai?  \n",
        "a) Zero-shot prompting  \n",
        "b) **Few-shot prompting with JSON examples**  \n",
        "c) Role prompting  \n",
        "d) Step-back prompting  \n",
        "**Explanation**: Examples se model format samajhta hai.\n",
        "\n",
        "#### Question 14\n",
        "Chain of Thought mein reasoning explain karne ka kya fayda hai?  \n",
        "a) Response lamba ho jata hai  \n",
        "b) **Model ko correct answer tak pahunchne mein madad milti hai**  \n",
        "c) Examples ki zarurat kam hoti hai  \n",
        "d) Computational cost kam hota hai  \n",
        "**Explanation**: Reasoning steps accuracy badhate hain.\n",
        "\n",
        "#### Question 15\n",
        "High temperature use karne ka ek drawback kya hai?  \n",
        "a) **Model incoherent responses de sakta hai**  \n",
        "b) Model hamesha same output deta hai  \n",
        "c) Output chhota ho jata hai  \n",
        "d) Prompt injection ka risk badhta hai  \n",
        "**Explanation**: Zyada randomness se coherence kam ho sakta hai.\n",
        "\n",
        "#### Question 16\n",
        "Tree of Thoughts (ToT) prompting model ko kya allow karta hai?  \n",
        "a) Single linear reasoning path follow karna  \n",
        "b) **Multiple reasoning paths simultaneously explore karna**  \n",
        "c) Code zyada efficiently generate karna  \n",
        "d) Token usage kam karna  \n",
        "**Explanation**: ToT complex tasks ke liye multiple paths deta hai.\n",
        "\n",
        "#### Question 17\n",
        "ReAct prompting mein kya combine hota hai?  \n",
        "a) **Reasoning aur acting loop mein**  \n",
        "b) Multiple models ek saath kaam karte hain  \n",
        "c) Text aur image inputs  \n",
        "d) Prompt engineering aur fine-tuning  \n",
        "**Explanation**: ReAct reasoning aur action ko integrate karta hai.\n",
        "\n",
        "#### Question 18\n",
        "Prompt attempts document karna kyun zaroori hai?  \n",
        "a) Legal requirements ke liye  \n",
        "b) **Changes track karne aur successful techniques samajhne ke liye**  \n",
        "c) Prompts share karne ke liye  \n",
        "d) Model performance badhane ke liye  \n",
        "**Explanation**: Documentation iterative improvement ke liye key hai.\n",
        "\n",
        "#### Question 19\n",
        "Code-related tasks ke liye LLMs use karte waqt kya caution rakhna chahiye?  \n",
        "a) **Model security vulnerabilities wala code generate kar sakta hai**  \n",
        "b) Model sirf Python mein code deta hai  \n",
        "c) Model hamesha optimized code deta hai  \n",
        "d) Model code explain nahi kar sakta  \n",
        "**Explanation**: Security risks review ke zariye check karne padte hain.\n",
        "\n",
        "#### Question 20\n",
        "Prompt engineering mein \"hallucination\" ka matlab kya hai?  \n",
        "a) Creative but irrelevant content generate karna  \n",
        "b) **Factually incorrect information dena**  \n",
        "c) Prompt ko repeat karna  \n",
        "d) Koi output na dena  \n",
        "**Explanation**: Hallucination factual errors ko refer karta hai.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LSE4S5g7L0rj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmu9e10wQpx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}